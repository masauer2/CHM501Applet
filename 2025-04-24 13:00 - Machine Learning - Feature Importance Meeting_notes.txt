=== 2025-04-24 13:00 - Machine Learning - Feature Importance Meeting ===
=== Project: Machine Learning Interpretability ===
Date: April 26, 2025
Attendees: Michael, Dr. A, Dr. B

Review of Feature Importance Concepts
The goal is to quantify how much each feature x_j contributes to the model’s output y_hat. Feature importance can be either local (for one prediction) or global (averaged over the dataset).
Permutation Importance
Idea: Randomly shuffle a feature and measure the drop in model performance. If performance drops significantly, the feature is important. Formalization:
Importance(x_j) = Performance(original) - Performance(shuffled(x_j))
- Pros: Model-agnostic, easy to compute. 
- Cons: Correlated features can mask true importance.
SHAP (Shapley Additive Explanations)
Based on cooperative game theory. Each feature’s contribution is its average marginal contribution across all possible feature combinations. Shapley value formula:
phi_j = sum over S subset of F without {j} of [ (|S|! * (|F|-|S|-1)!) / |F|! ] * (v(S union {j}) - v(S))

Where F is the set of all features, and v(S) is the model output when using features in subset S.
- Pros: Theoretically grounded, fair. 
- Cons: Expensive to compute exactly.
Gini Importance (for Decision Trees)

Measures how much a feature decreases node impurity across the tree. Importance is computed by summing the impurity reduction over all nodes where feature x_j is used.
Importance(x_j) = sum over nodes t where split on x_j of p(t) * delta_i(t)

Where p(t) is the proportion of samples reaching node t and delta_i(t) is the impurity decrease at node t.

- Pros: Fast to compute during training. 
- Cons: Biased toward features with more categories or high cardinality.
Integrated Gradients (for Neural Networks)
Computes the path integral of the gradients of the output along a straight path from a baseline input x’ to the actual input x. 
Formula: IntegratedGrad(x_j) = (x_j - x_j’) * integral from 0 to 1 of [partial f(x’ + alpha*(x - x’)) / partial x_j] d(alpha)
- Pros: Smooth, theoretically solid for deep networks. 
- Cons: Choosing a good baseline x’ can be tricky.
Action Items:
- Michael: Benchmark permutation and Gini importance on sample datasets.
- Dr. A: Prototype SHAP value approximation method for tree models.
- Dr. B: Investigate integrated gradient baselines for structured data.
