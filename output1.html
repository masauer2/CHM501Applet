
<script src="http://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js"></script>
<script src="jquery.jslatex.js"></script>
<script>
    $(function () { $(".latex").latex(); });
    </script>
<html>
<head>
<style>
        body {
            font-family: 'Segoe UI', 'Arial', sans-serif;
            font-size: 24px;
            color: #333333;
        }
    </style>
</head>
<br/><font size="10px"> === 2025-04-24 13:00 - Machine Learning - Feature Importance Meeting ===</font> <br/><br/> <body><br/>Attendees: Michael, Dr. A, Dr. B<br/><br/>Review of Feature Importance Concepts<br/>The goal is to quantify how much each feature x_j contributes to the model’s output y_hat. Feature importance can be either local (for one prediction) or global (averaged over the dataset).<br/>Permutation Importance<br/>Idea: Randomly shuffle a feature and measure the drop in model performance. If performance drops significantly, the feature is important. Formalization:<br/>Importance(x_j) = Performance(original) - Performance(shuffled(x_j))<br/><ul> <li> Pros: Model-agnostic, easy to compute.  </li> </ul><ul> <li> Cons: Correlated features can mask true importance. </li> </ul>SHAP (Shapley Additive Explanations)<br/>Based on cooperative game theory. Each feature’s contribution is its average marginal contribution across all possible feature combinations. Shapley value formula:<br/>phi_j = sum over S subset of F without j of [ (|S|! * (|F|-|S|-1)!) / |F|! ] * (v(S union j) - v(S))<br/><br/>Where F is the set of all features, and v(S) is the model output when using features in subset S.<br/><ul> <li> Pros: Theoretically grounded, fair.  </li> </ul><ul> <li> Cons: Expensive to compute exactly. </li> </ul>Gini Importance (for Decision Trees)<br/><br/>Measures how much a feature decreases node impurity across the tree. Importance is computed by summing the impurity reduction over all nodes where feature x_j is used.<br/>Importance(x_j) = sum over nodes t where split on x_j of p(t) * delta_i(t)<br/><br/>Where p(t) is the proportion of samples reaching node t and delta_i(t) is the impurity decrease at node t.<br/><br/><ul> <li> Pros: Fast to compute during training.  </li> </ul><ul> <li> Cons: Biased toward features with more categories or high cardinality. </li> </ul>Integrated Gradients (for Neural Networks)<br/>Computes the path integral of the gradients of the output along a straight path from a baseline input x’ to the actual input x. <br/>Formula: IntegratedGrad(x_j) = (x_j - x_j’) * integral from 0 to 1 of [partial f(x’ + alpha*(x - x’)) / partial x_j] d(alpha)<br/><ul> <li> Pros: Smooth, theoretically solid for deep networks.  </li> </ul><ul> <li> Cons: Choosing a good baseline x’ can be tricky. </li> </ul>Action Items:<br/><ul> <li> Michael: Benchmark permutation and Gini importance on sample datasets. </li> </ul><ul> <li> Dr. A: Prototype SHAP value approximation method for tree models. </li> </ul><ul> <li> Dr. B: Investigate integrated gradient baselines for structured data. </li> </ul><br/><font size="10px"> === 2025-04-25 10:00 - Mark Hayes Group Meeting ===</font> <br/><br/> <body><br/>Take a look at some papers<br/><br/><ul> <li> Tiwary 2020 - Adversarian Neural Networks </li> </ul><ul> <li> Matyushov 2020 - DEP Review Paper </li> </ul>
</body></body></html>
